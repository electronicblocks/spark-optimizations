{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08057f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89e9b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext,SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89998f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/10 19:15:31 WARN Utils: Your hostname, arphaxad-HP-Notebook resolves to a loopback address: 127.0.1.1; using 192.168.1.4 instead (on interface wlp3s0)\n",
      "24/04/10 19:15:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/10 19:15:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setAppName(\"optimisation\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea193181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:===================>                                       (1 + 2) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group by key\n",
    "data_sample = [(1,4),(2,2),(2,1),(3,5),(2,5),(2,10),(2,7),(3,4),(2,1),(2,4),(4,4)]\n",
    "rdd_sample = sc.parallelize(data_sample,3)\n",
    "rdd_sample.glom().collect()\n",
    "rdd_sample.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "211b700b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4),\n",
       " (2, 2),\n",
       " (2, 1),\n",
       " (3, 5),\n",
       " (2, 5),\n",
       " (2, 10),\n",
       " (2, 7),\n",
       " (3, 4),\n",
       " (2, 1),\n",
       " (2, 4),\n",
       " (4, 4)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rdd_sample.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e478b153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae5d35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:>                                                          (0 + 3) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(1, 4), (2, 2), (2, 1)],\n",
       " [(3, 5), (2, 5), (2, 10)],\n",
       " [(2, 7), (3, 4), (2, 1), (2, 4), (4, 4)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_sample.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59751a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_grouped = rdd_sample.groupByKey()# wide transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a41c5255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[15] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b83790c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [5, 4]\n",
      "1 [4]\n",
      "4 [4]\n",
      "2 [2, 1, 5, 10, 7, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8:=======================================>                   (2 + 1) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for item in rdd_grouped.collect():\n",
    "    print(item[0], [value for value in item[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dd6ad7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:===================>                                      (1 + 2) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(3, <pyspark.resultiterable.ResultIterable at 0x7c224254d360>)],\n",
       " [(1, <pyspark.resultiterable.ResultIterable at 0x7c224254c640>),\n",
       "  (4, <pyspark.resultiterable.ResultIterable at 0x7c224254d1e0>)],\n",
       " [(2, <pyspark.resultiterable.ResultIterable at 0x7c224254c9d0>)]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_grouped.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af03248e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_grouped.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98acb77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [5, 4]\n",
      "1 [4]\n",
      "4 [4]\n",
      "2 [2, 1, 5, 10, 7, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 12:>                                                         (0 + 3) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for item in rdd_grouped.collect():\n",
    "    print(item[0], [value for value in item[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1679335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "key_1 = ['a']* 10\n",
    "key_2 = ['b']* 6000000\n",
    "key_3 = ['c']* 800\n",
    "key_4 = ['d'] * 10000\n",
    "\n",
    "\n",
    "keys = key_1+key_2+key_3+key_4\n",
    "random.shuffle(keys)\n",
    "values_1  = list(np.random.randint(low = 1,high=100,size = len(key_1)))\n",
    "values_2  = list(np.random.randint(low = 1,high=100,size = len(key_2)))\n",
    "values_3  = list(np.random.randint(low = 1,high=100,size = len(key_3)))\n",
    "values_4  = list(np.random.randint(low = 1,high=100,size = len(key_4)))\n",
    "values = values_1+values_2+values_3+values_4\n",
    "\n",
    "pair_skew = list(zip(keys,values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df3bd6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into rdd\n",
    "rdd = sc.parallelize(pair_skew,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d58f7ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/10 21:08:20 WARN TaskSetManager: Stage 13 contains a task of very large size (16951 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_rdd_data = rdd.groupByKey().cache()# chache \n",
    "group_rdd_data.map(lambda pair:(pair[0],[i+10 for i in pair[1]])).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06729d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salting\n",
    "def salting(val):\n",
    "    tmp = val+\"_\"+str(random.randint(0,5))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f7672ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/10 21:23:14 WARN TaskSetManager: Stage 15 contains a task of very large size (16951 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#salted_rdd\n",
    "salted_rdd = rdd.map(lambda x:(salting(x[0]),x[1]))\n",
    "grouped_rdd_salted = salted_rdd.groupByKey().cache()\n",
    "grouped_rdd_salted.map(lambda pair:(pair[0],[i+10 for i in pair[1]])).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "538c063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/10 21:34:45 WARN TaskSetManager: Stage 17 contains a task of very large size (16951 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/04/10 21:34:49 WARN TaskSetManager: Stage 18 contains a task of very large size (16951 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/04/10 21:34:55 WARN TaskSetManager: Stage 19 contains a task of very large size (16951 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6010810"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_sort = rdd.sortByKey(ascending = False,numPartitions=4)\n",
    "rdd_sort.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "584820ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/10 21:37:27 WARN TaskSetManager: Stage 21 contains a task of very large size (16951 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/04/10 21:37:41 WARN TaskSetManager: Stage 22 contains a task of very large size (16951 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/04/10 21:37:54 WARN TaskSetManager: Stage 23 contains a task of very large size (16951 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6010810"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_sort = salted_rdd.sortByKey(ascending = False,numPartitions=4)\n",
    "rdd_sort.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ee8fd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, (3, 2)), (1, (4, 2)), (2, (3, 1))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join \n",
    "\n",
    "\n",
    "rdd1 = sc.parallelize([(2,3),(1,3),(1,4),(3,1),(5,1)],3)\n",
    "rdd2 = sc.parallelize([(4,3),(0,1),(1,2),(2,1)],2)\n",
    "join1 = rdd1.join(rdd2)\n",
    "join1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33f085a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join1.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddadb37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 28:==================================>                       (3 + 2) / 5]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[], [(1, (3, 2)), (1, (4, 2))], [(2, (3, 1))], [], []]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join1.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aedef19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/10 22:10:07 WARN TaskSetManager: Stage 29 contains a task of very large size (16951 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35600986935"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create sample data for join\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "key_1 = ['a']* 5\n",
    "key_2 = ['b']* 60\n",
    "key_3 = ['c']* 100\n",
    "\n",
    "\n",
    "\n",
    "keys = key_1+key_2+key_3\n",
    "random.shuffle(keys)\n",
    "values_1  = list(np.random.randint(low = 1,high=100,size = len(key_1)))\n",
    "values_2  = list(np.random.randint(low = 1,high=100,size = len(key_2)))\n",
    "values_3  = list(np.random.randint(low = 1,high=100,size = len(key_3)))\n",
    "\n",
    "values = values_1+values_2+values_3\n",
    "\n",
    "pair_data = list(zip(keys,values))\n",
    "rdd_small = sc.parallelize(pair_data,2)\n",
    "# join without salting\n",
    "\n",
    "rdd_join_noSalting = rdd.join(rdd_small)\n",
    "rdd_join_noSalting.map(lambda x:x[1][0]+x[1][1]).reduce(lambda a,b:a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eac761d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_join_noSalting.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dea9af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
